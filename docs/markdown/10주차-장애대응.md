# 장애 대응을 위한 부하 테스트

요즘, 뮤지컬 콘서트 티켓팅이 한창 뜨겁습니다.

티켓팅을 하는 동시 접속 유저의 수가 많을수록 높은 부하를 견뎌야 합니다.

또한, 높은 부하와 함께 예상치 못한 장애가 발생하기도 합니다.

이용자 경험을 중시하는 개발자라면, 높은 부하를 견뎌야하는 환경에서 어떤 방식의 노력이 필요할까요?

# 모니터링, 로깅과 추적

`높은 부하`와 동반하는 `장애 상황`에서 가장 중요한 액션 아이템이 있다면, **상황 인지**와 **전파**입니다.

먼저 빠른 **상황 인지**를 어떻게 할 수 있을까요?

가장 좋은 방법은 `높은 부하`나 잦은 `5xx 에러`가 뜨는 경우 `알림`이 오면 상황을 바로 인지할 수 있을 것입니다.

혹은, 서버나 어플리케이션의 상태 지표를 시각화하여 대쉬보드로 직접 확인해볼 수도 있습니다.

그러기 위해선 **모니터링 툴**이 필요합니다.

## 1. 모니터링

대표적인 모니터링할 수 있는 지표(metric)는 다음 사항들이 있습니다.

- 서버 리소스
    - CPU, Memory, Disk, Load ...
- 어플리케이션 모니터링
    - Request 수, Response(200, 400, 500) 통계, Latency ...
- 네트워크
    - Bandwidth, Packet Rate, Error rate, ...

서버 노드로 들어가 지표를 확인하기 위해 일일히 `ps -ef`,  `htop` 명령어를 친다던지,

에러 로그를 확인하기 위해 `tail -f /var/log/application-error.log`를 직접 검색한다면, 너무도 많은 시간이 소요될 것입니다.

이런 모니터링을 위해 `monitoring-stack`이 있는데, 모니터링을 위한 툴들의 집합입니다.

대표적으로 `prometheus-grafana-(loki)`, `ELK/EFK`, `datadog(유료)`를 주로 사용합니다.

본문에서는 전자를 이용하여 모니터링 스택을 구성해보겠습니다.

### prometheus-grafana-loki

프로메테우스는 오픈소스 모니터링을 위한 시스템입니다.

HTTP 서버, 메트릭 저장을 위한 시계열 DB 등으로 구성되어 있습니다.

![11.1](https://github.com/hpp-backend-15/java-concert-joonhyeokyang/blob/step18/docs/img/11-1.png)

Application/Node에 exporter를 설치하여 프로메테우스 서버로 보내면, 이를 수집, 저장합니다.

`그라파나`는 오픈소스 대시보드입니다.

`prometheus, loki, tempo`로부터 저장한 지표들을 집계하여 시각화합니다.

`loki`는 로그들을 수집하여 집계, 검색(쿼리)하는 서버입니다.

`tempo`는 분산된 정보를 모아서 추적(트레이싱)할 수 있게 합니다.

`spring`의 경우, `actuator`를 이용하여 `prometheus`에 서버 지표를 보낼 수 있지만,

저의 경우는 `opentelemetry-spring-boot-starter`를 사용하여, `otel-collector`에 보낸뒤,

otel-collector는 수집한 정보를 prometheus, loki, tempo로 보내고, 각 서버로부터 grafana가 정보를 시각화합니다.

각 서버에 메트릭, 로그, 트레이스 등을 직접 보내지 않고, open-telemetry를 사용한 이유는 인터페이스를 제공해주기 때문입니다.

open-telemetry는 Vendor, tool-agnostic하기에 확장성있게 학습할 수 있다고 판단해서입니다.

(즉, otel 서버 하나 잘 구축해놓으면 어떤 언어를 사용하는 언어/프레임워크던 일단 otel에 전송하면 되기 때문에)

![11.2](https://github.com/hpp-backend-15/java-concert-joonhyeokyang/blob/step18/docs/img/11-2.png)

## 2. 로깅과 추적

MSA 환경에서 로그의 파악, 추적을 위해서 로깅 규칙 만들고, 관리합니다.

분산 환경에서 어느 부분이 병목인지, 어디서 슬로우 쿼리가 발생하는지 파악하기 위하여 추적을 위한 `jaeger`와 같은 추적 기능도 도입합니다.

추가적으로 다음 필드들을 이용하여 분산 환경에서 추적을 용이하게 할 수 있습니다.

| 필드 이름             | 설명                          |
|-------------------|-----------------------------|
| `timestamp`       | 로그 발생 시간 (ISO 8601 형식 권장)   |
| `level`           | 로그 레벨 (INFO, WARN, ERROR 등) |
| `trace_id`        | 분산 추적 식별자 (요청 단위로 고유)       |
| `span_id`         | 서비스/작업 단위의 고유 식별자           |
| `parent_span_id`  | 상위 span_id (없다면 `null`)     |
| `service_name`    | 로그를 기록한 서비스 이름              |
| `message`         | 사람이 읽을 수 있는 로그 메시지          |
| `additional_data` | 추가적으로 필요한 데이터(JSON 형식)      |

또한, 각 서버 노드들의 로그가 한 곳에서 관리할 수 있도록 합니다.

Loki와 promtail(exporter)를 이용합니다.

로키는 분산 환경의 어플리케이션/인프라 **로그** 집계시스템입니다.

또한 어떤 쿼리 로그가 발생했는지 **Loki**를 이용하여 시간, 어플리케이션 별로 분석하고 조회할 수 있습니다.

이를 통하여 분산환경에서 각 노드에 직접 접속하여 쿼리 로그를 확인하는 불편한 일이 없도록 합니다.

[다음 깃허브](https://github.com/ruanbekker/docker-monitoring-stack-gpnc?tab=readme-ov-file)를 이용하여 모니터링 스택을 설치했습니다.

# 부하 테스트 가상 시나리오

우리는 `부하가 일어나는 환경의 파악을 위한` 과정을 거쳤습니다.

이제 실제로 `부하가 일어나는 환경`을 구성해보겠습니다.

11월 29일 20주년 `지킬앤 하이드` 공연이
있습니다. [정보](https://www.kopis.or.kr/por/db/pblprfr/pblprfrView.do?menuId=MNU_00020&mt20Id=PF250136&period=w&signgu_code=%5E11&genre_code=GGGA&tabv=pstv&search=box)

약 30회의 공연, 1766석의 좌석이 있습니다.

특정 캐스팅의 공연이 인기있고, 특정 좌석에 몰릴 수 있습니다.

## (1) 예상 TPS (Transaction Per Second)

- 예상 유저는 2만명
- 유저는 `공연 가능일좌 선택` - `공연 좌석 선택` - `예약` - `충전` - `결제`하므로, 약 5번 트랜잭션 수행.
- 티켓팅 특성상 예매 10초 이내 대부분의 요청 유입
- 예상 TPS = (20,000 * 5) / 10 = 10,000

1. 대기열 트래픽

- 모든 유저는 인입시 `대기열 등록` - `대기열 확인`의 과정을 거칩니다.
- 서버가 부하를 견딜 있도록 대기열 통과 유저의 숫자를 조절합니다. (1000~2000 TPS)

2. 공연 가능일좌/좌석 선택

- 1000~2000 TPS를 견딜 수 있을 정도로 구성합니다.

3. 예약

- 예약은 한정된 유저만 성공하기에 100~200 TPS를 견딜 수 있을 정도로 구성합니다. (대부분의 유저가 실패하고 10%~20%만 성공한다는 가정)

4. 충전

- 예약과 같습니다.

5. 결제

- 예약과 같습니다.

## (2) 평균/중간/최대 응답시간

예약 시스템의 가장 최대 목표는 최소한 정당하게 대기한 유저들이 `500` 에러, 응답없음을 겪지 않도록 해 유저 경험을 향상시키는 것입니다.
그러므로 대기열 트래픽이 아닌 유저들의 latency p(95)가 500ms이하로 하는 것을 목표로 시나리오를 잡겠습니다.

## (3) 다량의 트래픽 유입 시 동시성 이슈 발생 여부

동시성 이슈는 `예약`에서 발생합니다.
`예약`은 같은 좌석에 예약하려는 유저가 많아 발생하게 됩니다.

이렇게 동시성 이슈가 발생하는 곳에 처리할 수 있는 방법들 중 가장 대중적인 **redis 분산락**과 **낙관락**을 혼합하여 미리 대비해놓은 상태입니다.

# 부하 테스트 가상 시나리오 사전 준비

## 준비 사항

- APP
    - HW
        - CPU: 2 cpu
        - Memory: 2048MB

- DB
    - 콘서트 500 개
    - 콘서트 일자 = 500 * 20 = 10,000 개
    - 콘서트 좌석 = 10,000 * 1000 = 10,000,000 개
      - 이중 콘서트 1개의 20,000개(20일 * 1000 좌석) 좌석에 예약 시도
      - 이중 인기 있는 좌석 4,000개 좌석은 80% 유저가 시도, 나머지 16,000 좌석은 20% 유저가 시도 
    - 유저 ~2만명
    - HW
        - CPU: 2 cpu
        - Memory: 2048MB

<details>

<summary>사전 준비</summary>

<details>
    <summary>docker-compose에서 자원 제한 하는 법</summary>

```yaml
deploy:
  resources:
    limits:
      cpus: '2'
      memory: 2048m
    reservations:
      cpus: '2'
      memory: 2048m
```
</details>


<details>
    <summary>DB 스크립트 </summary>

```sql
DELIMITER $$
CREATE PROCEDURE IF NOT EXISTS loopInsertUser()
BEGIN
    DECLARE i INT DEFAULT 2;
    DECLARE performance_dates_id INT DEFAULT 1;

    WHILE i <= 20000
        DO
            -- 데이터 삽입
            INSERT INTO concert.users (version, users_account_balance, users_account_modified_at)
            VALUES (0, 0, now());

            SET i = i + 1;
        END WHILE;
END $$

DELIMITER ;

DELIMITER $$
CREATE PROCEDURE IF NOT EXISTS loopInsertConcert()
BEGIN
    DECLARE i INT DEFAULT 2;

    WHILE i <= 500
        DO
            -- 데이터 삽입
            INSERT INTO concert.concerts (performer)
            VALUES (concat('performer', i));

            SET i = i + 1;
        END WHILE;
END $$


DELIMITER $$
CREATE PROCEDURE IF NOT EXISTS loopInsertConcertPd()
BEGIN
    DECLARE i INT DEFAULT 2;
    DECLARE j INT DEFAULT 1;

    WHILE i <= 500
        DO
            WHILE j <= 20
                DO
                    insert into concert.performance_dates(performance_dates_dates, concerts_id)
                        VALUE (subdate(now(), j), i);
                    SET j = j + 1;
                end while;
            SET i = i + 1;
            SET j = 1;
        END WHILE;
END $$

DELIMITER ;


DELIMITER $$
CREATE PROCEDURE IF NOT EXISTS loopInsertConcertSeats()
BEGIN
    DECLARE i INT DEFAULT 2;
    DECLARE j INT DEFAULT 1;
    DECLARE k INT DEFAULT 1;
    DECLARE performance_dates_id INT DEFAULT 1;

    WHILE i <= 500
        DO
            WHILE j <= 20
                DO
                    while k <= 1000
                        DO
                            -- 데이터 삽입
                            INSERT INTO concert.seats (version, last_reserved_at, performance_dates_id, seats_price,
                                                       seats_status)
                            VALUES (0, NULL, performance_dates_id, 0, 'AVAILABLE');
                            set k = k + 1;
                        end while;
                    set performance_dates_id = performance_dates_id + 1;
                    SET k = 1;
                    SET j = j + 1;
                end while;
            SET i = i + 1;
            SET j = 1;
        END WHILE;
END $$

DELIMITER ;

```

</details>



</details>


이 외 인프라는 따로 설정하지 않았습니다.

## 부하 테스트 시나리오 스크립트

1. 공연 예매 시작 전
- 모든 유저 대기열 등록 요청 (best effort)

2. 공연 좌석 예매 시작
- 대기열 상태 조회 요청 (~ 1,000TPS)
- 15초에 500명씩 입장 (놀이공원식)
- 좌석 예약 요청 (~ 2,000TPS)
    - 좌석 예약 요청시 몰리는 좌석 (인기 좌석) 있도록

3. 결제
- 좌석 결제 요청(~ 100TPS)



